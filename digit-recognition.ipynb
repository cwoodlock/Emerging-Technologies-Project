{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will try and classify and identify the hand written numbers that are in the mnist dataset. We will first use the training set to train the network and then we will use the test set to test the accuracy of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we will have to do is import the packages that we are going to be using in this program/notebook. The packages that I will be including are;\n",
    "1. numpy\n",
    "2. gzip\n",
    "3. sklearn preprocessing\n",
    "4. keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Colm\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import numpy as np \n",
    "import gzip #import gzip for unpacking images and the labels \n",
    "import sklearn.preprocessing as pre #For encoding categorical variables\n",
    "import keras as kr #this will be used for the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start building the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start building the neural network. The first thing we need to do is create a model. By creating the model like this, in layers, we can tweak different parts of it to optimize the performance of the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start a neural network, building it by layers\n",
    "model = kr.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a hidden layer with 1000 neurons and an input layer with 784\n",
    "#Decided to use relu for activation function as it is tends to avoid dead neurons during backpropagation\n",
    "#https://datascience.stackexchange.com/questions/26475/why-is-relu-used-as-an-activation-function\n",
    "#https://ai.stackexchange.com/questions/6468/why-to-prefer-relu-over-linear-activation-functions\n",
    "model.add(kr.layers.Dense(units=1000, activation='relu', input_dim=784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add neurons ro the output layer\n",
    "model.add(kr.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the graph.\n",
    "#optimiser times admam=771 sgd=515 adadelta=851 https://www.dlology.com/blog/quick-notes-on-how-to-choose-optimizer-in-keras/\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the gzipped files and read as bytes.\n",
    "#Adapted from : https://docs.python.org/2/library/gzip.html\n",
    "with gzip.open('data/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    train_img = f.read()\n",
    "\n",
    "with gzip.open('data/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    train_lbl = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the images and labels into memory\n",
    "train_img = ~np.array(list(train_img[16:])).reshape(60000, 28, 28).astype(np.uint8) / 255.0\n",
    "train_lbl =  np.array(list(train_lbl[ 8:])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten the array\n",
    "inputs = train_img.reshape(60000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding categorical variables\n",
    "#Encode the labels into binary format\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html\n",
    "encoder = pre.LabelBinarizer()\n",
    "#the sze of the array for each category\n",
    "encoder.fit(train_lbl)\n",
    "#encode each label as binary outputs\n",
    "#https://github.com/scikit-learn/scikit-learn/issues/5536\n",
    "outputs = encoder.transform(train_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[1 0 0 0 0 0 0 0 0 0]]\n",
      "1 [[0 1 0 0 0 0 0 0 0 0]]\n",
      "2 [[0 0 1 0 0 0 0 0 0 0]]\n",
      "3 [[0 0 0 1 0 0 0 0 0 0]]\n",
      "4 [[0 0 0 0 1 0 0 0 0 0]]\n",
      "5 [[0 0 0 0 0 1 0 0 0 0]]\n",
      "6 [[0 0 0 0 0 0 1 0 0 0]]\n",
      "7 [[0 0 0 0 0 0 0 1 0 0]]\n",
      "8 [[0 0 0 0 0 0 0 0 1 0]]\n",
      "9 [[0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# print out each array\n",
    "#In the console you will now see each number and its corressponding binary number\n",
    "for i in range(10):\n",
    "    print(i, encoder.transform([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.8893 - acc: 0.7830\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.4631 - acc: 0.8760\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.3949 - acc: 0.8896\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.3627 - acc: 0.8968\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.3420 - acc: 0.9015\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.3271 - acc: 0.9064- ETA: 0s - loss: 0.3272 - 11s 189us/step - loss: 0.3271 - acc: 0.9064\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.3158 - acc: 0.9096\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.3056 - acc: 0.9131\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.2971 - acc: 0.91480s - loss: 0.2982 - a\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.2893 - acc: 0.9168\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.2828 - acc: 0.9190\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 0.2749 - acc: 0.9207\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.2685 - acc: 0.9235\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.2624 - acc: 0.9248\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.2559 - acc: 0.9274\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 0.2497 - acc: 0.9287\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.2436 - acc: 0.9306\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.2373 - acc: 0.9331\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.2319 - acc: 0.9346\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.2272 - acc: 0.9369\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 13s 221us/step - loss: 0.2215 - acc: 0.9367\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.2160 - acc: 0.9388\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.2115 - acc: 0.94050s - loss: 0.2119 - acc: \n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.2058 - acc: 0.9429\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.2014 - acc: 0.9438\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.1972 - acc: 0.9447\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.1929 - acc: 0.9457\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.1883 - acc: 0.9473\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.1842 - acc: 0.9485\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.1804 - acc: 0.9502\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.1765 - acc: 0.95050s - loss: 0.175\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.1732 - acc: 0.9515\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.1692 - acc: 0.9529\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.1661 - acc: 0.9542\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.1625 - acc: 0.9548\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.1600 - acc: 0.9552\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.1563 - acc: 0.9563\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.1536 - acc: 0.9570\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.1508 - acc: 0.9580\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.1477 - acc: 0.9592\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.1452 - acc: 0.9594\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.1424 - acc: 0.9606\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.1400 - acc: 0.9617\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.1376 - acc: 0.9618\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.1352 - acc: 0.9632\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.1329 - acc: 0.9632\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.1308 - acc: 0.96400s - loss: 0.1314 - ac\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.1287 - acc: 0.9646\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.1264 - acc: 0.9654\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.1244 - acc: 0.9662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x963d05e908>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#start the training set up the \n",
    "model.fit(inputs, outputs, epochs=50, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the gzipped test images and labels\n",
    "with gzip.open('data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    test_img = f.read()\n",
    "\n",
    "with gzip.open('data/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    test_lbl = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store each image and label into memory\n",
    "test_img = ~np.array(list(test_img[16:])).reshape(10000, 784).astype(np.uint8) / 255.0\n",
    "test_lbl =  np.array(list(test_lbl[ 8:])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acccuracy is:  9637\n"
     ]
    }
   ],
   "source": [
    "accuracy =(encoder.inverse_transform(model.predict(test_img)) == test_lbl).sum()\n",
    "print(\"Acccuracy is: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the accuracy of the program is about 96%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
